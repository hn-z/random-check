import shap
import torch
import numpy as np

def create_tabular_prediction_wrapper(model, background_embeddings):
    """
    Create a wrapper function that only varies tabular features while keeping 
    image embeddings fixed at their mean values
    """
    def predict_tabular_only(fea_tabular_batch):
        """
        Prediction function that takes only tabular features as input
        """
        batch_size = fea_tabular_batch.shape[0]
        
        # Use mean embeddings as background for image features
        mean_emb_prcl = background_embeddings['mean_emb_prcl']
        mean_emb_bldg = background_embeddings['mean_emb_bldg']
        
        # Create fixed embeddings for the batch
        emb_prcl_batch = torch.tensor(mean_emb_prcl).repeat(batch_size, 1)
        emb_bldg_batch = torch.tensor(mean_emb_bldg).repeat(batch_size, 1)
        
        # Convert tabular features to tensor
        fea_tabular_tensor = torch.tensor(fea_tabular_batch, dtype=torch.float32)
        
        # Forward pass through model
        model.eval()
        with torch.no_grad():
            predictions = model.forward_with_embeddings(
                emb_prcl_batch, 
                emb_bldg_batch, 
                fea_tabular_tensor
            )
        
        return predictions.numpy()
    
    return predict_tabular_only

# Calculate background embeddings from training data
def calculate_background_embeddings(train_dataset, model):
    """Calculate mean embeddings from training data"""
    all_emb_prcl = []
    all_emb_bldg = []
    
    # Sample from training data
    sample_size = min(1000, len(train_dataset))
    indices = np.random.choice(len(train_dataset), sample_size, replace=False)
    
    model.eval()
    with torch.no_grad():
        for idx in indices:
            loc_key, emb_prcl, emb_bldg, fea_tabular, target = train_dataset[idx]
            
            # Process through model's embedding layers if needed
            # Or use raw embeddings if they're already processed
            all_emb_prcl.append(emb_prcl.numpy())
            all_emb_bldg.append(emb_bldg.numpy())
    
    return {
        'mean_emb_prcl': np.mean(all_emb_prcl, axis=0),
        'mean_emb_bldg': np.mean(all_emb_bldg, axis=0)
    }

# Usage
background_embeddings = calculate_background_embeddings(train_dataset, model)
tabular_pred_func = create_tabular_prediction_wrapper(model, background_embeddings)

# Extract tabular features for SHAP analysis
def extract_tabular_features(dataset, indices):
    """Extract tabular features from dataset"""
    tabular_features = []
    for idx in indices:
        _, _, _, fea_tabular, _ = dataset[idx]
        tabular_features.append(fea_tabular.numpy())
    return np.array(tabular_features)

# Get background and test tabular features
background_indices = np.random.choice(len(train_dataset), 100, replace=False)
test_indices = range(min(500, len(test_dataset)))  # Adjust as needed

X_tabular_background = extract_tabular_features(train_dataset, background_indices)
X_tabular_test = extract_tabular_features(test_dataset, test_indices)

# Calculate SHAP values
explainer = shap.Explainer(tabular_pred_func, X_tabular_background)
shap_values = explainer(X_tabular_test)



def analyze_tabular_shap_for_significant_cases(model, dataset, tabular_feature_names):
    """
    Analyze SHAP values for cases where tabular features cause significant changes
    """
    # Get predictions from image-only and combined models
    # (You'll need to implement image-only prediction)
    
    # Calculate prediction differences
    pred_differences = []
    all_tabular_features = []
    significant_indices = []
    
    for idx in range(len(dataset)):
        loc_key, emb_prcl, emb_bldg, fea_tabular, target = dataset[idx]
        
        # Get combined model prediction
        with torch.no_grad():
            combined_pred = model.forward_with_embeddings(
                emb_prcl.unsqueeze(0), 
                emb_bldg.unsqueeze(0), 
                fea_tabular.unsqueeze(0)
            ).item()
            
            # Get image-only prediction (using mean tabular features)
            mean_tabular = torch.tensor(background_embeddings['mean_tabular'])
            image_only_pred = model.forward_with_embeddings(
                emb_prcl.unsqueeze(0), 
                emb_bldg.unsqueeze(0), 
                mean_tabular.unsqueeze(0)
            ).item()
        
        pred_diff = abs(combined_pred - image_only_pred)
        
        if pred_diff > threshold:  # Define your threshold
            pred_differences.append(combined_pred - image_only_pred)
            all_tabular_features.append(fea_tabular.numpy())
            significant_indices.append(idx)
    
    # Calculate SHAP for significant cases
    if len(significant_indices) > 0:
        X_significant = np.array(all_tabular_features)
        shap_values_significant = explainer(X_significant)
        
        # Analyze results
        feature_impact = pd.DataFrame({
            'feature': tabular_feature_names,
            'mean_abs_shap': np.mean(np.abs(shap_values_significant.values), axis=0),
            'correlation_with_change': [
                np.corrcoef(shap_values_significant.values[:, i], pred_differences)[0, 1]
                for i in range(len(tabular_feature_names))
            ]
        })
        
        return feature_impact, shap_values_significant, significant_indices
    
    return None, None, []

# Usage
feature_impact, shap_values, significant_indices = analyze_tabular_shap_for_significant_cases(
    model, test_dataset, tabular_feature_names
)

if feature_impact is not None:
    print("Tabular features driving significant prediction changes:")
    print(feature_impact.sort_values('mean_abs_shap', ascending=False))



import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

def analyze_feature_importance(shap_values, tabular_feature_names, X_tabular_test):
    """
    Basic feature importance analysis from SHAP values
    """
    # Calculate mean absolute SHAP values for each feature
    mean_abs_shap = np.mean(np.abs(shap_values.values), axis=0)
    
    # Create importance DataFrame
    importance_df = pd.DataFrame({
        'feature': tabular_feature_names,
        'mean_abs_shap': mean_abs_shap,
        'mean_shap': np.mean(shap_values.values, axis=0),  # Can be positive/negative
        'std_shap': np.std(shap_values.values, axis=0)
    }).sort_values('mean_abs_shap', ascending=False)
    
    print("Top 10 Most Important Tabular Features:")
    print(importance_df.head(10))
    
    return importance_df

# Usage
importance_df = analyze_feature_importance(shap_values, tabular_feature_names, X_tabular_test)



import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

def analyze_feature_importance(shap_values, tabular_feature_names, X_tabular_test):
    """
    Basic feature importance analysis from SHAP values
    """
    # Calculate mean absolute SHAP values for each feature
    mean_abs_shap = np.mean(np.abs(shap_values.values), axis=0)
    
    # Create importance DataFrame
    importance_df = pd.DataFrame({
        'feature': tabular_feature_names,
        'mean_abs_shap': mean_abs_shap,
        'mean_shap': np.mean(shap_values.values, axis=0),  # Can be positive/negative
        'std_shap': np.std(shap_values.values, axis=0)
    }).sort_values('mean_abs_shap', ascending=False)
    
    print("Top 10 Most Important Tabular Features:")
    print(importance_df.head(10))
    
    return importance_df

# Usage
importance_df = analyze_feature_importance(shap_values, tabular_feature_names, X_tabular_test)


def create_waterfall_plots(shap_values, X_tabular_test, tabular_feature_names, 
                          case_indices=None, n_cases=5):
    """
    Create waterfall plots for individual cases
    """
    if case_indices is None:
        # Select cases with highest absolute SHAP sum
        total_shap_impact = np.sum(np.abs(shap_values.values), axis=1)
        case_indices = np.argsort(total_shap_impact)[-n_cases:]
    
    for i, case_idx in enumerate(case_indices):
        plt.figure(figsize=(12, 8))
        
        # Create SHAP explanation object for waterfall plot
        explanation = shap.Explanation(
            values=shap_values.values[case_idx],
            base_values=shap_values.base_values[case_idx] if hasattr(shap_values, 'base_values') else 0,
            data=X_tabular_test[case_idx],
            feature_names=tabular_feature_names
        )
        
        shap.waterfall_plot(explanation, max_display=10)
        plt.title(f'SHAP Waterfall Plot - Case {case_idx}')
        plt.tight_layout()
        plt.show()

# Usage
create_waterfall_plots(shap_values, X_tabular_test, tabular_feature_names)




def create_feature_groups(tabular_feature_names):
    """
    Define which features belong to the same categorical variable
    """
    feature_groups = {}
    numerical_features = []
    
    # Example mapping - adjust based on your actual feature names
    feature_groups['location_type'] = [f for f in tabular_feature_names if f.startswith('location_type_')]
    feature_groups['building_type'] = [f for f in tabular_feature_names if f.startswith('building_type_')]
    feature_groups['coverage_type'] = [f for f in tabular_feature_names if f.startswith('coverage_type_')]
    feature_groups['risk_category'] = [f for f in tabular_feature_names if f.startswith('risk_cat_')]
    
    # Identify numerical features (those not in any categorical group)
    all_categorical_features = []
    for group_features in feature_groups.values():
        all_categorical_features.extend(group_features)
    
    numerical_features = [f for f in tabular_feature_names if f not in all_categorical_features]
    
    # Add numerical features as individual groups
    for num_feat in numerical_features:
        feature_groups[num_feat] = [num_feat]
    
    return feature_groups, numerical_features

# Usage
feature_groups, numerical_features = create_feature_groups(tabular_feature_names)
print("Feature Groups:")
for group_name, features in feature_groups.items():
    print(f"  {group_name}: {features}")
def aggregate_categorical_shap_values(shap_values, tabular_feature_names, feature_groups):
    """
    Aggregate SHAP values for categorical features
    """
    aggregated_shap = {}
    aggregated_feature_names = []
    
    for group_name, group_features in feature_groups.items():
        # Get indices of features in this group
        group_indices = [tabular_feature_names.index(feat) for feat in group_features if feat in tabular_feature_names]
        
        if len(group_indices) == 1:
            # Single feature (numerical or single category)
            aggregated_shap[group_name] = shap_values.values[:, group_indices[0]]
        else:
            # Multiple features (categorical with multiple categories)
            # Sum absolute values to get total contribution of the categorical variable
            group_shap_values = shap_values.values[:, group_indices]
            
            # Method 1: Sum of absolute values
            aggregated_shap[group_name] = np.sum(np.abs(group_shap_values), axis=1)
            
            # Method 2: Sum of raw values (can be negative)
            # aggregated_shap[group_name] = np.sum(group_shap_values, axis=1)
            
            # Method 3: Max absolute value (dominant category)
            # aggregated_shap[group_name] = group_shap_values[np.arange(len(group_shap_values)), 
            #                                                 np.argmax(np.abs(group_shap_values), axis=1)]
        
        aggregated_feature_names.append(group_name)
    
    # Convert to array format
    aggregated_shap_array = np.column_stack([aggregated_shap[name] for name in aggregated_feature_names])
    
    return aggregated_shap_array, aggregated_feature_names, aggregated_shap

# Usage
aggregated_shap_values, aggregated_feature_names, shap_dict = aggregate_categorical_shap_values(
    shap_values, tabular_feature_names, feature_groups
)


def plot_combined_feature_importance(aggregated_shap_values, aggregated_feature_names):
    """
    Plot feature importance with combined categorical features
    """
    # Calculate mean absolute SHAP values
    mean_abs_shap = np.mean(np.abs(aggregated_shap_values), axis=0)
    
    # Create DataFrame
    importance_df = pd.DataFrame({
        'feature': aggregated_feature_names,
        'importance': mean_abs_shap,
        'mean_shap': np.mean(aggregated_shap_values, axis=0)
    }).sort_values('importance', ascending=True)
    
    # Plot
    plt.figure(figsize=(10, 8))
    colors = ['red' if x < 0 else 'blue' for x in importance_df['mean_shap']]
    
    plt.barh(range(len(importance_df)), importance_df['importance'], color=colors, alpha=0.7)
    plt.yticks(range(len(importance_df)), importance_df['feature'])
    plt.xlabel('Mean Absolute SHAP Value')
    plt.title('Combined Feature Importance (Categorical + Numerical)')
    plt.grid(True, alpha=0.3)
    
    # Add legend
    from matplotlib.patches import Patch
    legend_elements = [Patch(facecolor='blue', alpha=0.7, label='Positive Average Impact'),
                      Patch(facecolor='red', alpha=0.7, label='Negative Average Impact')]
    plt.legend(handles=legend_elements)
    
    plt.tight_layout()
    plt.show()
    
    return importance_df

# Usage
combined_importance = plot_combined_feature_importance(aggregated_shap_values, aggregated_feature_names)
